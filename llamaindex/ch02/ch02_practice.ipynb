{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50db8e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx2txt in /opt/anaconda3/envs/myenv/lib/python3.12/site-packages (0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install docx2txt\n",
    "#docx2txt : .docx 파일에서 텍스트 추출하기 위한 파서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c34a09fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document : 1\n",
      "this is the content of file 1.\n",
      "{'file_path': '/Users/baghyeonmi/Documents/GitHub/LLM_RAG/llamaindex/ch02/sample_docs/file1.txt', 'file_name': 'file1.txt', 'file_type': 'text/plain', 'file_size': 30, 'creation_date': '2025-08-23', 'last_modified_date': '2025-08-23'}\n",
      "\n",
      "\n",
      "Document : 2\n",
      "this is the content of file 3.\n",
      "{'file_path': '/Users/baghyeonmi/Documents/GitHub/LLM_RAG/llamaindex/ch02/sample_docs/file3.txt', 'file_name': 'file3.txt', 'file_type': 'text/plain', 'file_size': 30, 'creation_date': '2025-08-23', 'last_modified_date': '2025-08-23'}\n",
      "\n",
      "\n",
      "Document : 3\n",
      "this is the content of file 4.\n",
      "{'file_path': '/Users/baghyeonmi/Documents/GitHub/LLM_RAG/llamaindex/ch02/sample_docs/sub_sample_docs/file4.txt', 'file_name': 'file4.txt', 'file_type': 'text/plain', 'file_size': 30, 'creation_date': '2025-08-23', 'last_modified_date': '2025-08-23'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "#[데이터 리더]\n",
    "\n",
    "#simple_docs에 있는 모든 파일 읽어오기\n",
    "#documents = SimpleDirectoryReader(\"sample_docs\").load_data()\n",
    "\n",
    "#simpel_docs 아래의 모든 파일 읽어오기(recursice=True 설정)\n",
    "documents = SimpleDirectoryReader(\"sample_docs\", recursive=True).load_data()\n",
    "\n",
    "#특정 파일 형식만 로딩하기\n",
    "documents = SimpleDirectoryReader(\"sample_docs\", required_exts=[\".txt\", \".pdf\"], recursive=True).load_data()\n",
    "for i, document in enumerate(documents):\n",
    "    print(f\"Document : {i+1}\")\n",
    "    print(document.text)\n",
    "    print(document.metadata)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e2501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-readers-database==0.3.0 in ./ch02_env/lib/python3.12/site-packages (0.3.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-readers-database==0.3.0) (0.12.52.post1)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (3.12.15)\n",
      "Requirement already satisfied: aiosqlite in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2025.7.0)\n",
      "Requirement already satisfied: httpx in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.3.0)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (3.5)\n",
      "Requirement already satisfied: nltk>3.8.1 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (3.9.1)\n",
      "Requirement already satisfied: numpy in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (11.3.0)\n",
      "Requirement already satisfied: platformdirs in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (4.3.8)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in ./ch02_env/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2.0.43)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.11.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (4.14.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./ch02_env/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./ch02_env/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./ch02_env/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./ch02_env/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./ch02_env/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./ch02_env/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./ch02_env/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.20.1)\n",
      "Requirement already satisfied: griffe in ./ch02_env/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.12.1)\n",
      "Requirement already satisfied: jinja2 in ./ch02_env/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (3.1.6)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.4.0)\n",
      "Requirement already satisfied: idna>=2.0 in ./ch02_env/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (3.10)\n",
      "Requirement already satisfied: click in ./ch02_env/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (8.2.1)\n",
      "Requirement already satisfied: joblib in ./ch02_env/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./ch02_env/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2025.7.34)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./ch02_env/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./ch02_env/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./ch02_env/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./ch02_env/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./ch02_env/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./ch02_env/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in ./ch02_env/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./ch02_env/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./ch02_env/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in ./ch02_env/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (25.0)\n",
      "Requirement already satisfied: colorama>=0.4 in ./ch02_env/lib/python3.12/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.4.6)\n",
      "Requirement already satisfied: anyio in ./ch02_env/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./ch02_env/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./ch02_env/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./ch02_env/lib/python3.12/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./ch02_env/lib/python3.12/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (3.0.2)\n",
      "Requirement already satisfied: pymysql in ./ch02_env/lib/python3.12/site-packages (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-readers-database==0.3.0\n",
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12b79d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: llama-index\n",
      "Version: 0.11.11\n",
      "Summary: Interface between LLMs and your data\n",
      "Home-page: https://llamaindex.ai\n",
      "Author: Jerry Liu\n",
      "Author-email: jerry@llamaindex.ai\n",
      "License: MIT\n",
      "Location: /Users/baghyeonmi/Documents/GitHub/LLM_RAG/llamaindex/ch02/ch02_env/lib/python3.12/site-packages\n",
      "Requires: llama-index-agent-openai, llama-index-cli, llama-index-core, llama-index-embeddings-openai, llama-index-indices-managed-llama-cloud, llama-index-legacy, llama-index-llms-openai, llama-index-multi-modal-llms-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index-readers-file, llama-index-readers-llama-parse, nltk\n",
      "Required-by: \n",
      "---\n",
      "Name: llama-index-readers-database\n",
      "Version: 0.3.0\n",
      "Summary: llama-index readers database integration\n",
      "Home-page: \n",
      "Author: Your Name\n",
      "Author-email: you@example.com\n",
      "License: MIT\n",
      "Location: /Users/baghyeonmi/Documents/GitHub/LLM_RAG/llamaindex/ch02/ch02_env/lib/python3.12/site-packages\n",
      "Requires: llama-index-core\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show llama-index llama-index-readers-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46ff41c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document 1:\n",
      "ID 8a3672bd-f4d2-4606-aecd-60fec6dfb60b\n",
      "ROW id: 1, name: Alice, email: alice@example.com, age: 30\n",
      "--------------------------------------------------\n",
      "document 2:\n",
      "ID 4391b72d-26fd-43a5-8288-ebe7768d1e76\n",
      "ROW id: 2, name: Bob, email: bob@example.com, age: 25\n",
      "--------------------------------------------------\n",
      "document 3:\n",
      "ID 9cb3c4ca-f61c-4159-9584-ab85c7a92d48\n",
      "ROW id: 3, name: Charlie, email: charlie@example.com, age: 35\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#[데이터 커텍터]\n",
    "#from llama_index.readers.sql import SQLDatabaseReader\n",
    "from sqlalchemy import create_engine\n",
    "from llama_index.readers.database import DatabaseReader\n",
    "\n",
    "#MySQL 연결 정보 직접 입력\n",
    "scheme = \"mysql+pymysql\"\n",
    "host = \"localhost\"\n",
    "port = \"3306\"\n",
    "user = \"root\"\n",
    "dbname = \"test_db\"\n",
    "password = \"4344\"\n",
    "\n",
    "connection_string = f\"{scheme}://{user}:{password}@{host}:{port}/{dbname}\"\n",
    "\n",
    "engine = create_engine(connection_string)\n",
    "reader = DatabaseReader(sql_database=engine)\n",
    "\n",
    "#데이터 로드\n",
    "query = \"SELECT * FROM users\"\n",
    "documents = reader.load_data(query=query)\n",
    "\n",
    "for idx, doc in enumerate(documents):\n",
    "    print(f\"document {idx + 1}:\")\n",
    "    print(f\"ID {doc.id_}\")\n",
    "    print(f\"ROW {doc.text}\")\n",
    "    print(\"-\"* 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64ff44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: 5d99188a-1ed3-441f-8a8b-da4972af71c7\n",
      "Text: 영화 '기생충'은 가난한 가족인 기누에가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다.처음에는\n",
      "평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다.박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는\n",
      "오랫동안 숨어 살던 남자가 있다는 반전이 있습니다이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다.결국\n",
      "극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n"
     ]
    }
   ],
   "source": [
    "#[텍스트분할-문서]\n",
    "from llama_index.core import Document\n",
    "\n",
    "#텍스트 데이터를 기반으로 문서 생성\n",
    "document_text = (\"영화 '기생충'은 가난한 가족인 기누에가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다.\"\n",
    "                 \"처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다.\"\n",
    "                 \"박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는 반전이 있습니다\"\n",
    "                 \"이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다.\"\n",
    "                 \"결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\")\n",
    "\n",
    "document = Document(text=document_text)\n",
    "\n",
    "#메타데이터 추가\n",
    "document.metadata = {'author':'영화 해설', 'subject':'기생충 줄거리'}\n",
    "\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b26ce31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "생성된 노드들\n",
      "노드 1:영화 '기생충'은 가난한 가족인 기누에가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다.\n",
      "    메타데이터:{'type': '영화 줄거리', 'genre': '드라마', 'node_id': 1}\n",
      "노드 2:처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다.\n",
      "    메타데이터:{'type': '영화 줄거리', 'genre': '드라마', 'node_id': 2}\n",
      "노드 3:박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는 반전이 있습니다이 사실을\n",
      "    메타데이터:{'type': '영화 줄거리', 'genre': '드라마', 'node_id': 3}\n",
      "노드 4:알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다.\n",
      "    메타데이터:{'type': '영화 줄거리', 'genre': '드라마', 'node_id': 4}\n",
      "노드 5:결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n",
      "    메타데이터:{'type': '영화 줄거리', 'genre': '드라마', 'node_id': 5}\n"
     ]
    }
   ],
   "source": [
    "#[텍스트 분할-노드]\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "\n",
    "#chunk_size=글자수, chunk_overlap=겹치는글자수\n",
    "parser = SimpleNodeParser(chunk_size=80, chunk_overlap=0)\n",
    "nodes = parser.get_nodes_from_documents([document])\n",
    "\n",
    "print(\"\\n생성된 노드들\")\n",
    "for idx, node in enumerate(nodes, start=1):\n",
    "    node.metadata = {'type':'영화 줄거리', 'genre':'드라마', 'node_id':idx}\n",
    "    print(f\"노드 {idx}:{node.text}\")\n",
    "    print(f\"    메타데이터:{node.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98018bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청크 1: 영화 '기생충'은 가난한 가족인 기누에가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다.처음에는 평화로워 보이지만, 이들의\n",
      "[토큰 개수:79]\n",
      "\n",
      "총 생성된 청크 개수: 3\n",
      "청크 2: 거짓말이 쌓이며 긴장감이 점점 고조됩니다.박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는\n",
      "[토큰 개수:78]\n",
      "\n",
      "총 생성된 청크 개수: 3\n",
      "청크 3: 반전이 있습니다이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다.결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n",
      "[토큰 개수:79]\n",
      "\n",
      "총 생성된 청크 개수: 3\n"
     ]
    }
   ],
   "source": [
    "#[라마인덱스-openai(cl100k_base) 토크나이저 사용]\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "import tiktoken\n",
    "\n",
    "#cl100k_base 토크나이저 로드\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "token_splitter = TokenTextSplitter(chunk_size=80, chunk_overlap=0)\n",
    "chunks = token_splitter.split_text(document_text)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    token_count = len(tokenizer.encode(chunk)) #각 청크의 토큰 개수 계산\n",
    "    print(f\"청크 {i+1}: {chunk}\\n[토큰 개수:{token_count}]\\n\")\n",
    "    print(f\"총 생성된 청크 개수: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fdeb6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "문서 단위 검색 결과\n",
      "문서 검색 응답:이 영화의 반전은 박 사장네 집에 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는 사실입니다.\n",
      "-결과 1:영화 '기생충'은 가난한 가족인 기누에가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다.처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다.박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는 반전이 있습니다이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다.결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n",
      "\n",
      "노드 단위 검색 결과\n",
      "노드 검색 응답:비극적인 결말로 이어지는 극한 상황에서 벌어지는 사건이 이 영화의 반전입니다.\n",
      "-결과 1:결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n",
      "-결과 2:처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다.\n"
     ]
    }
   ],
   "source": [
    "#[openAPI-문서/노드 단위 결과 비교]\n",
    "from llama_index.core import VectorStoreIndex, Document, Settings\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "import os\n",
    "#openai 설정\n",
    "llm = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"], model=\"get-4o-mini\", system_prompt=\"반드시 한국어로 답변하세요.\")\n",
    "\n",
    "#문서 단위 검색을 위한 전체 문서 인덱스 생성\n",
    "full_doc_index = VectorStoreIndex.from_documents([document], llm=llm)\n",
    "\n",
    "#노드 단위 검색을 위한 인덱스 생성\n",
    "node_index = VectorStoreIndex(nodes, llm=llm)\n",
    "\n",
    "#검색 비교\n",
    "query_text = '이 영화의 반전은?'\n",
    "\n",
    "#문서 단위 검색\n",
    "print(\"\\n문서 단위 검색 결과\")\n",
    "doc_query_engine = full_doc_index.as_query_engine()\n",
    "doc_response = doc_query_engine.query(query_text)\n",
    "print(f\"문서 검색 응답:{doc_response.response}\")\n",
    "if doc_response.source_nodes:\n",
    "    for idx, document in enumerate(doc_response.source_nodes, start=1):\n",
    "        print(f\"-결과 {idx}:{document.node.text}\")\n",
    "\n",
    "#노드 단위 검색\n",
    "print(\"\\n노드 단위 검색 결과\")\n",
    "node_query_engine = node_index.as_query_engine()\n",
    "node_response = node_query_engine.query(query_text)\n",
    "print(f\"노드 검색 응답:{node_response.response}\")\n",
    "if node_response.source_nodes:\n",
    "    for idx, document in enumerate(node_response.source_nodes, start=1):\n",
    "        print(f\"-결과 {idx}:{document.node.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80460a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기본 청킹 크기:1024\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "parser = SimpleNodeParser()\n",
    "print(f\"기본 청킹 크기:{parser.chunk_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e8d009f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===토큰 기반 분할 결과===\n",
      "chunk 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 \n",
      "\n",
      "chunk 2: 취업하면서 벌어지는 이야기입니다. 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 \n",
      "\n",
      "chunk 3: 쌓이며 긴장감이 점점 고조됩니다. 그러나 이 영화의 반전은 지하실에서 시작됩니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#[텍스트분할-토큰 단위]\n",
    "#토큰 단위 분할 : 단어나 구두점 등 텍스트를 구성하는 기본적인 단위\n",
    "\n",
    "sample_text = \"영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. 그러나 이 영화의 반전은 지하실에서 시작됩니다.\"\n",
    "\n",
    "token_splitter = TokenTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "token_chunks = token_splitter.split_text(sample_text)\n",
    "\n",
    "print(\"===토큰 기반 분할 결과===\")\n",
    "for i, chunk in enumerate(token_chunks):\n",
    "    print(f\"chunk {i+1}:\", chunk.strip(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6663614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===문장 기반 분할 결과===\n",
      "chunk 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 \n",
      "\n",
      "chunk 2: 벌어지는 이야기입니다. \n",
      "\n",
      "chunk 3: 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. \n",
      "\n",
      "chunk 4: 그러나 이 영화의 반전은 지하실에서 시작됩니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#[텍스트분할-문장 단위]\n",
    "#토큰 단위 보다 문장을 불안전하게 나뉠 가능성이 낮으며, 문맥의 흐름을 보다 자연스럽게 유지할 수 있다는 장점\n",
    "\n",
    "from llama_index.core.node_parser.text.sentence import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=50, chunk_overlap=0)\n",
    "sentence_chunks = splitter.split_text(sample_text)\n",
    "\n",
    "print(\"===문장 기반 분할 결과===\")\n",
    "for i, chunk in enumerate(sentence_chunks):\n",
    "    print(f\"chunk {i+1}:\", chunk.strip(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9067cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===의미 기반 분할 결과===\n",
      "chunk 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. \n",
      "\n",
      "chunk 2: 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. \n",
      "\n",
      "chunk 3: 그러나 이 영화의 반전은 지하실에서 시작됩니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#[텍스트분할-의미 단위]\n",
    "#문장/토큰수 기준이 아닌 문맥의 의미를 고려하여 텍스트를 적절한 단위로 분할\n",
    "\n",
    "#[OPENAI 임베딩 -> 유료]\n",
    "#텍스트 의미적 유사도 계산, 이를 바탕으로 의미가 자연스럽게 유지되는 지점에서 텍스트 분할\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embed_model = OpenAIEmbedding()\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1,\n",
    "    breakpoint_percentile_threshold=95,\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "chunks = splitter.sentence_splitter(sample_text)\n",
    "print(\"===의미 기반 분할 결과===\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"chunk {i+1}:\", chunk.strip(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1aab58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./ch02_env/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./ch02_env/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./ch02_env/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./ch02_env/lib/python3.12/site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in ./ch02_env/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./ch02_env/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./ch02_env/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./ch02_env/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.1.8-cp37-abi3-macosx_11_0_arm64.whl.metadata (703 bytes)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./ch02_env/lib/python3.12/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./ch02_env/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./ch02_env/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./ch02_env/lib/python3.12/site-packages (from requests->transformers) (2025.8.3)\n",
      "Downloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.8-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: safetensors, hf-xet, filelock, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [transformers][0m [transformers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.19.1 hf-xet-1.1.8 huggingface-hub-0.34.4 safetensors-0.6.2 tokenizers-0.21.4 transformers-4.55.4\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading llama_index_embeddings_huggingface-0.6.0-py3-none-any.whl.metadata (458 bytes)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in ./ch02_env/lib/python3.12/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.34.4)\n",
      "Collecting llama-index-core<0.14,>=0.13.0 (from llama-index-embeddings-huggingface)\n",
      "  Using cached llama_index_core-0.13.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n",
      "  Downloading sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (3.12.15)\n",
      "Requirement already satisfied: aiosqlite in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (2025.7.0)\n",
      "Requirement already satisfied: httpx in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (3.5)\n",
      "Requirement already satisfied: nltk>3.8.1 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (11.3.0)\n",
      "Requirement already satisfied: platformdirs in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (4.3.8)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in ./ch02_env/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (2.0.43)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.11.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (4.14.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./ch02_env/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./ch02_env/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./ch02_env/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./ch02_env/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./ch02_env/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./ch02_env/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./ch02_env/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./ch02_env/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.20.1)\n",
      "Requirement already satisfied: griffe in ./ch02_env/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.12.1)\n",
      "Requirement already satisfied: jinja2 in ./ch02_env/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (3.1.6)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in ./ch02_env/lib/python3.12/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.4.0)\n",
      "Requirement already satisfied: idna>=2.0 in ./ch02_env/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (3.10)\n",
      "Requirement already satisfied: filelock in ./ch02_env/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.19.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./ch02_env/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./ch02_env/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.1.8)\n",
      "Requirement already satisfied: click in ./ch02_env/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (8.2.1)\n",
      "Requirement already satisfied: joblib in ./ch02_env/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./ch02_env/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (2025.7.34)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./ch02_env/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./ch02_env/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./ch02_env/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./ch02_env/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./ch02_env/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./ch02_env/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (2025.8.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./ch02_env/lib/python3.12/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.55.4)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading torch-2.8.0-cp312-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting scikit-learn (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading scikit_learn-1.7.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading scipy-1.16.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./ch02_env/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./ch02_env/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.6.2)\n",
      "Requirement already satisfied: greenlet>=1 in ./ch02_env/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (3.2.4)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./ch02_env/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./ch02_env/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (3.26.1)\n",
      "Requirement already satisfied: colorama>=0.4 in ./ch02_env/lib/python3.12/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.4.6)\n",
      "Requirement already satisfied: anyio in ./ch02_env/lib/python3.12/site-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./ch02_env/lib/python3.12/site-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./ch02_env/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./ch02_env/lib/python3.12/site-packages (from anyio->httpx->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./ch02_env/lib/python3.12/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (3.0.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading llama_index_embeddings_huggingface-0.6.0-py3-none-any.whl (8.9 kB)\n",
      "Using cached llama_index_core-0.13.3-py3-none-any.whl (7.6 MB)\n",
      "Downloading sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
      "Downloading torch-2.8.0-cp312-none-macosx_11_0_arm64.whl (73.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.1-cp312-cp312-macosx_12_0_arm64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.16.1-cp312-cp312-macosx_14_0_arm64.whl (20.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: mpmath, threadpoolctl, sympy, scipy, torch, scikit-learn, sentence-transformers, llama-index-core, llama-index-embeddings-huggingface\n",
      "\u001b[2K  Attempting uninstall: llama-index-core91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m6/9\u001b[0m [sentence-transformers]\n",
      "\u001b[2K    Found existing installation: llama-index-core 0.12.52.post1[0m \u001b[32m6/9\u001b[0m [sentence-transformers]\n",
      "\u001b[2K    Uninstalling llama-index-core-0.12.52.post1:m━━━━━━━━━━━━━\u001b[0m \u001b[32m6/9\u001b[0m [sentence-transformers]\n",
      "\u001b[2K      Successfully uninstalled llama-index-core-0.12.52.post1━\u001b[0m \u001b[32m6/9\u001b[0m [sentence-transformers]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9/9\u001b[0m [llama-index-embeddings-huggingface]ore]]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-question-gen-openai 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.13.3 which is incompatible.\n",
      "llama-index 0.11.11 requires llama-index-core<0.12.0,>=0.11.10, but you have llama-index-core 0.13.3 which is incompatible.\n",
      "llama-index-program-openai 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.13.3 which is incompatible.\n",
      "llama-index-agent-openai 0.3.4 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.13.3 which is incompatible.\n",
      "llama-index-multi-modal-llms-openai 0.2.3 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.13.3 which is incompatible.\n",
      "llama-index-embeddings-openai 0.2.5 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.13.3 which is incompatible.\n",
      "llama-index-cli 0.3.1 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.13.3 which is incompatible.\n",
      "llama-index-readers-llama-parse 0.3.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.13.3 which is incompatible.\n",
      "llama-index-readers-file 0.2.2 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.13.3 which is incompatible.\n",
      "llama-index-readers-database 0.3.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.13.3 which is incompatible.\n",
      "llama-index-llms-openai 0.2.16 requires llama-index-core<0.12.0,>=0.11.7, but you have llama-index-core 0.13.3 which is incompatible.\n",
      "llama-index-indices-managed-llama-cloud 0.6.0 requires llama-index-core<0.12.0,>=0.11.13.post1, but you have llama-index-core 0.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed llama-index-core-0.13.3 llama-index-embeddings-huggingface-0.6.0 mpmath-1.3.0 scikit-learn-1.7.1 scipy-1.16.1 sentence-transformers-5.1.0 sympy-1.14.0 threadpoolctl-3.6.0 torch-2.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d184b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===의미 기반 분할 결과===\n",
      "chunk 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. \n",
      "\n",
      "chunk 2: 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. \n",
      "\n",
      "chunk 3: 그러나 이 영화의 반전은 지하실에서 시작됩니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#[허깅페이스 임베딩 -> 무료]\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1,\n",
    "    breakpoint_percentile_threshold=95,\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "chunks = splitter.sentence_splitter(sample_text)\n",
    "print(\"===의미 기반 분할 결과===\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"chunk {i+1}:\", chunk.strip(), \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ch02_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
